<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Horvitz-Thompson estimator</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>



<!-- MathJax scripts -->
<script type="text/javascript" src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



</head>

<body>
<h2>Horvitz-Thompson estimator</h2>

<hr/>

<p>This is a method for estimating the <strong>mean</strong> and <strong>total</strong> of a population of finite size \( N \), from a sample of size \( n \), where different individuals in the population have different probabilities of being included in the sample but the same expected value.</p>

<p>The true value of the population total (\( \tau \)) and the population mean (\( \mu \)) are,</p>

<p>\[  \tau = \sum_{i=1}^N y_i  \qquad\qquad  \mu = \frac{1}{N} \sum_{i=1}^N y_i  \]</p>

<p>where,</p>

<p>\( y_i \) is the value of individual \( i \)</p>

<p>\( \pi_i \) is the <strong>inclusion probablilty</strong> for individual \( i \) (the probability that individual \( i \) is in the sample)</p>

<p>The Horvitz-Thompson estimators are,</p>

<p>\[  \widehat{\tau} = \sum_{i=1}^n \frac{y_i}{\pi_i}  \qquad\qquad  \widehat{\mu} = \frac{1}{N} \sum_{i=1}^n \frac{y_i}{\pi_i}   \]</p>

<p>So the higher the probability that individual \( i \) is in the sample, the less weight the response \( y_i \) is given when estimating the total.</p>

<hr/>

<h3>Expected value</h3>

<p>To work this out we need to re-express the estimator as a function of the indicator variable, \( z_i \),</p>

<p>\[  \widehat{\tau} = \sum_{i=1}^N z_i \frac{y_i}{\pi_i}  \]</p>

<p>where,</p>

<p>\[ 
z_i = \begin{cases}
1 & \mbox{if the $i$th individual is in the sample} \\
0 & \mbox{otherwise}
\end{cases}
 \]</p>

<p>The indicator variable follows the <a href="Bernoulli distribution.html">Bernoulli distribution</a> with probability \( \pi_i \), so the expected value of \( z_i \) is,</p>

<p>\[  \mbox{E}\left[ z_i \right] = \pi_i  \]</p>

<p>The <a href="Expected value.html">expected value</a> of the estimator is therefore given by,</p>

<p>\[  
\mbox{E}\left[ \widehat{\tau} \right] 
= \mbox{E}\left[ \sum_{i=1}^N z_i \frac{y_i}{\pi_i} \right] 
= \sum_{i=1}^N \mbox{E}\left[ z_i \frac{y_i}{\pi_i} \right] 
= \sum_{i=1}^N \frac{y_i}{\pi_i} \mbox{E}\left[ z_i \right] 
= \sum_{i=1}^N \frac{y_i}{\pi_i} \pi_i 
= \sum_{i=1}^N y_i 
= \tau 
 \]</p>

<p>which shows that it is unbiased.</p>

<hr/>

<h3>Variance</h3>

<p>For this we also need the variance of \( z_i \),</p>

<p>\[  \mbox{Var}\left[ z_i \right] = \pi_i(1-\pi_i)  \]</p>

<p>and the <a href="Covariance.html">covariance</a> of \( z_i \) and \( z_j \),</p>

<p>\[  \mbox{Cov}\left( z_i, z_j \right) = \mbox{E}\left[ z_i z_j \right] - \mbox{E}\left[ z_i \right] \mbox{E}\left[ z_j \right] = \pi_{ij} - \pi_i \pi_j  \]</p>

<p>where \( \pi_{ij} \) is the probability that individuals \( i \) an \( j \) are both in the sample.</p>

<p>The <a href="Variance.html">variance</a> of the estimator is therefore given by,</p>

<p>\[  
\begin{align}
   \mbox{Var}\left[ \widehat{\tau} \right] 
&= \mbox{Var}\left[ \sum_{i=1}^N z_i \frac{y_i}{\pi_i} \right] \\
&= \sum_{i=1}^N \left( \frac{y_i}{\pi_i} \right)^2 \mbox{Var}\left[ z_i \right]
   + \sum_{i=1}^N \sum_{j>i}^N \left( \frac{y_i}{\pi_i} \frac{y_j}{\pi_j} \right) \mbox{Cov}\left[ z_i, z_j \right] \\
&= \sum_{i=1}^N \left( \frac{y_i}{\pi_i} \right)^2 \pi_i(1-\pi_i)
   + \sum_{i=1}^N \sum_{j>i}^N \left( \frac{y_i}{\pi_i} \frac{y_j}{\pi_j} \right) \left( \pi_{ij} - \pi_i \pi_j \right) \\
&= \sum_{i=1}^N \frac{ (1-\pi_i) }{ \pi_i } y_i^2
   + \sum_{i=1}^N \sum_{j>i}^N \frac{ \left( \pi_{ij} - \pi_i \pi_j \right) }{\pi_i \pi_j} y_i y_j
\end{align}
 \]</p>

<hr/>

<p><a href="index.html#H">(back to H)</a> </p>

<p><a href="index.html">(back to index)</a> </p>

</body>

</html>

