
## Exponential family

********************************************************************************

$$ L(\theta, \phi) = \prod_{i=1}^n \exp\left[ \frac{y_i\theta_i - b(\theta_i)}{a(\phi)} + c(y_i,\phi) \right] $$

where,

$$ \mbox{E}\left[y\right] = \mu = b'(\theta) $$

$$ \mbox{Var}\left[y\right] = b''(\theta)a(\phi) $$

So $b'(\cdot)$ is the inverse link function, which implies,

$$ \theta = g(\mu) = \eta = X\beta $$

#### Derivatives

$$ \frac{\partial\mu}{\partial\theta} = b''(\theta) \implies \frac{\partial\theta}{\partial\mu} = \frac{1}{b''(\theta)} $$

$$ \frac{\partial\eta}{\partial\mu} = g'(\mu) \implies \frac{\partial\mu}{\partial\eta} = \frac{1}{g'(\mu)} $$

$$ \frac{\partial\eta}{\partial\beta_j} = x_j $$

********************************************************************************

### Log likelihood

$$ \ell(\theta, \phi) = \ell(\beta, \phi) = \sum_{i=1}^n \frac{y_i\theta_i - b(\theta_i)}{a(\phi)} + c(y_i,\phi) $$

#### First derivative

$$ \frac{ \partial\ell }{ \partial\theta } = \sum_{i=1}^n \frac{y_i - b'(\theta_i)}{a(\phi)} $$

$$
  \frac{ \partial\ell }{ \partial\beta_j } 
= \sum_{i=1}^n \frac{ \partial\ell }{ \partial\beta_j }  
= \sum_{i=1}^n \frac{ \partial\ell }{ \partial\theta_i } \frac{ \partial\theta_i }{ \partial\mu_i } \frac{ \partial\mu_i }{ \partial\eta_i } \frac{ \partial\eta_i }{ \partial\beta_j } 
= \sum_{i=1}^n \frac{y_i - b'(\theta_i)}{a(\phi)} \frac{1}{b''(\theta_i)} \frac{1}{g'(\mu_i)} x_{ij}
$$

$$ = \sum_{i=1}^n \frac{y_i - \mbox{E}\left[y_i\right]}{\mbox{Var}\left[y_i\right]} \frac{1}{g'(\mu_i)} x_{ij} = X^TV(y-\mu) $$

where,

$$ V = Diag\left( \frac{1}{\mbox{Var}\left[y_1\right]g'(\mu_1)} \cdots \frac{1}{\mbox{Var}\left[y_n\right]g'(\mu_n)} \right) $$

#### Second derivative

$$ \frac{ \partial^2\ell }{ \partial\theta^2 } = -\frac{b''(\theta)}{a(\phi)} $$

********************************************************************************

### The score statistic

The first derivative of the likelihood is called the score statistic, and can be regarded as a random variable,

$$ U = \frac{ \partial }{ \partial\theta } \ell(\theta ; Y) = \frac{Y - b'(\theta)}{a(\phi)} $$

The second derivative of the likelihood (i.e. the first derivative of the score statistic) can also be regarded as a random variable,

$$ U' = \frac{ \partial^2 }{ \partial\theta^2 } \ell(\theta ; Y) $$

The expected value of the score statistic is straightforward, given $\mbox{E}\left[y\right] = b'(\theta)$,

$$ \mbox{E}\left[U\right] = 0 $$

The variance of the score statistic is given by,

$$ \mbox{Var}\left[U\right] = \mbox{E}\left[U^2\right] = -\mbox{E}\left[U'\right] = -\mbox{E}\left[ \frac{ \partial^2 }{ \partial\theta^2 } \ell(\theta ; Y) \right] $$

which is the <a href="Maximum likelihood.html#Fisher information">Fisher information</a>.

********************************************************************************
